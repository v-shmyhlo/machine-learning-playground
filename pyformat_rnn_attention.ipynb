{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datasets.python_format as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "  def __init__(self, num_units):\n",
    "    self.encoder_fw = tf.nn.rnn_cell.GRUCell(num_units=num_units)\n",
    "    self.encoder_bw = tf.nn.rnn_cell.GRUCell(num_units=num_units)\n",
    "    \n",
    "  def train(self, inputs, seq_len):\n",
    "    (encoder_fw_outputs, encoder_bw_outputs), (encoder_fw_state, encoder_bw_state) = tf.nn.bidirectional_dynamic_rnn(\n",
    "      self.encoder_fw, \n",
    "      self.encoder_bw, \n",
    "      inputs=inputs,\n",
    "      sequence_length=seq_len,\n",
    "      dtype=tf.float32)\n",
    "\n",
    "    return encoder_fw_outputs, encoder_fw_state\n",
    "  \n",
    "class Decoder(object):\n",
    "  def __init__(self, encoder_states, encoder_seq_len, num_units):\n",
    "    decoder_fw = tf.nn.rnn_cell.GRUCell(num_units=num_units)\n",
    "    \n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "      num_units, \n",
    "      encoder_states,\n",
    "      memory_sequence_length=encoder_seq_len)\n",
    "    \n",
    "    decoder_fw = tf.contrib.seq2seq.AttentionWrapper(\n",
    "      decoder_fw, \n",
    "      attention_mechanism,\n",
    "      attention_layer_size=num_units)\n",
    "    \n",
    "    self.decoder_fw = decoder_fw\n",
    "    self.projection_layer = tf.layers.Dense(dataset.vocab_size, use_bias=False)\n",
    "    \n",
    "  def train(self, initial_state, inputs, seq_len):\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "      inputs, \n",
    "      seq_len)\n",
    "\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "      self.decoder_fw, \n",
    "      helper, \n",
    "      self.decoder_fw.zero_state(batch_size, tf.float32).clone(cell_state=initial_state),\n",
    "      output_layer=self.projection_layer)\n",
    "\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "      decoder,\n",
    "      impute_finished=True)\n",
    "\n",
    "    logits = outputs.rnn_output\n",
    "    translations = outputs.sample_id\n",
    "    return logits, translations\n",
    "  \n",
    "  def infer(self, initial_state, max_iterations):\n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "      lambda ids: tf.one_hot(ids, dataset.vocab_size),\n",
    "      tf.fill([batch_size], dataset.sos), \n",
    "      dataset.eos,\n",
    "    )\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "      self.decoder_fw, \n",
    "      helper, \n",
    "      self.decoder_fw.zero_state(batch_size, tf.float32).clone(cell_state=initial_state),\n",
    "      output_layer=self.projection_layer)\n",
    "      \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "      decoder, \n",
    "      impute_finished=True,\n",
    "      maximum_iterations=max_iterations)\n",
    "    \n",
    "    logits = outputs.rnn_output\n",
    "    translations = outputs.sample_id\n",
    "    return logits, translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 32\n",
    "max_time = None\n",
    "\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "  lambda: dataset.gen(min_len=3, max_len=7), \n",
    "  (tf.int32, tf.int32), \n",
    "  ([None], [None]),\n",
    ")\n",
    "ds = ds.map(lambda source, target: (\n",
    "  (tf.concat([[dataset.sos], source, [dataset.eos]], 0), tf.size(source) + 2), \n",
    "  (tf.concat([[dataset.sos], target, [dataset.eos]], 0), tf.size(target) + 2),\n",
    "))\n",
    "ds = ds.padded_batch(\n",
    "  batch_size, \n",
    "  padded_shapes=(([None], []), ([None], [])), \n",
    "  padding_values=((dataset.pad, 0), (dataset.pad, 0)))\n",
    "\n",
    "iterator = ds.make_one_shot_iterator()\n",
    "(source, source_seq_len), (target, target_seq_len) = iterator.get_next()\n",
    "\n",
    "encoder_inputs = source\n",
    "encoder_seq_len = source_seq_len\n",
    "decoder_inputs = target[:, :-1]\n",
    "decoder_targets = target[:, 1:]\n",
    "decoder_seq_len = target_seq_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_num_units = 256\n",
    "encoder = Encoder(encoder_num_units)\n",
    "\n",
    "encoder_outputs, encoder_state = encoder.train(\n",
    "  tf.one_hot(encoder_inputs, dataset.vocab_size),\n",
    "  encoder_seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_num_units = 256\n",
    "decoder = Decoder(encoder_outputs, encoder_seq_len, decoder_num_units)\n",
    "\n",
    "decoder_logits, _ = decoder.train(\n",
    "  encoder_state,\n",
    "  tf.one_hot(decoder_inputs, dataset.vocab_size),\n",
    "  decoder_seq_len\n",
    ")\n",
    "\n",
    "max_iterations = tf.round(tf.reduce_max(encoder_seq_len) * 2)\n",
    "_, translations = decoder.infer(\n",
    "  encoder_state,\n",
    "  max_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_ent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "  labels=decoder_targets, \n",
    "  logits=decoder_logits)\n",
    "\n",
    "loss_mask = tf.sequence_mask(decoder_seq_len, dtype=tf.float32)\n",
    "loss = tf.reduce_sum(cross_ent * loss_mask) / batch_size\n",
    "\n",
    "predicted = tf.argmax(tf.reshape(decoder_logits, [-1, dataset.vocab_size]), axis=1, output_type=tf.int32)\n",
    "actual = tf.reshape(decoder_targets, [-1])\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, actual), tf.float32))\n",
    "\n",
    "global_step = tf.get_variable('global_step', initializer=0, trainable=False)\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_log/pyformat_rnn_attention/model\n",
      "step: 1800, loss: 2.2008, accuracy: 99.43%, learning rate: 0.001\n",
      "model saved: tf_log/pyformat_rnn_attention/model\n",
      "step: 2000, loss: 0.5558, accuracy: 99.72%, learning rate: 0.001\n",
      "model saved: tf_log/pyformat_rnn_attention/model\n"
     ]
    }
   ],
   "source": [
    "steps = 2000\n",
    "lr = 0.001\n",
    "log_interval = 200\n",
    "save_interval = 200\n",
    "log_path = os.path.join('tf_log', 'pyformat_rnn_attention')\n",
    "model_name = os.path.join(log_path, 'model')\n",
    "checkpoint_filename = tf.train.latest_checkpoint(log_path)\n",
    "restore = checkpoint_filename is not None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  if restore:\n",
    "    saver.restore(sess, checkpoint_filename)\n",
    "  else:\n",
    "    sess.run(init)\n",
    "  \n",
    "  feed_dict = {learning_rate: lr}\n",
    "  \n",
    "  for i in range(sess.run(global_step), steps + 1):\n",
    "    sess.run(train, feed_dict)\n",
    "  \n",
    "    if i % log_interval == 0:\n",
    "      l, a = sess.run([loss, accuracy], feed_dict)\n",
    "      print('step: {}, loss: {:.4f}, accuracy: {:.2f}%, learning rate: {}'.format(i, l, a * 100, lr))\n",
    "      \n",
    "    if i % save_interval == 0:\n",
    "      save_path = saver.save(sess, model_name)\n",
    "      print('model saved: {}'.format(save_path))\n",
    "      \n",
    "  dlv = sess.run(decoder_logits, feed_dict)\n",
    "  sb, tb, pb = sess.run([encoder_inputs, target, translations], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} {} {}<f>voluptatibus<n>ipsum<n>Alias\n",
      "voluptatibus ipsum Alias\n",
      "voluptatibus ipsum Alias\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "s = sb[i]\n",
    "t = tb[i]\n",
    "p = pb[i]\n",
    "\n",
    "s = dataset.decode(s)\n",
    "t = dataset.decode(t)\n",
    "p = dataset.decode(p)\n",
    "\n",
    "s = s.split('<s>')[1].split('</s>')[0]\n",
    "t = t.split('<s>')[1].split('</s>')[0]\n",
    "p = p.split('</s>')[0]\n",
    "\n",
    "print(s)\n",
    "print(t)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
