{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check all special symbols used as strings\n",
    "# TODO: beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = {\n",
    "  '<pad>':    0,\n",
    "  '<format>': 1, \n",
    "  '<next>':   2, \n",
    "  '<start>':  3, \n",
    "  '<end>':    4, \n",
    "  '{':        5, \n",
    "  '}':        6,\n",
    "  ' ':        7\n",
    "}\n",
    "\n",
    "sym2id = {sym: i + len(special_symbols) for i, sym in enumerate(string.ascii_letters)}\n",
    "sym2id = {**special_symbols, **sym2id}\n",
    "id2sym = {sym2id[sym]: sym for sym in sym2id}\n",
    "\n",
    "vocab_size = len(string.ascii_letters) + len(special_symbols)\n",
    "assert vocab_size == len(sym2id) and vocab_size == len(id2sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(template, subs):\n",
    "  input = ['<start>'] + list(template) + ['<format>']\n",
    "  for sub in subs:\n",
    "    input += list(sub) + ['<next>']\n",
    "  input[-1] = '<end>'\n",
    "  output = ['<start>'] + list(template.format(*subs)) + ['<end>']\n",
    "  return np.array([sym2id[x] for x in input]), np.array([sym2id[x] for x in output])\n",
    "\n",
    "words = ['hello', 'world', 'boy', 'real', 'talk', 'something', 'might', 'be', 'wrong', 'just', 'random', 'words']\n",
    "words_2 = ['MY', 'NAME', 'IS', 'NOT', 'IMPORTANT', 'I', 'JUST', 'WORK', 'HERE']\n",
    "def sample_dataset():\n",
    "  n_words = np.random.randint(7)\n",
    "  sampled = [np.random.choice(words) for _ in range(n_words)]\n",
    "  text = ' {} '.join(sampled)\n",
    "  subs = [np.random.choice(words_2) for _ in range(n_words - 1)]\n",
    "  return text, subs\n",
    "\n",
    "def next_batch(batch_size):\n",
    "  inputs = []\n",
    "  inputs_len = []\n",
    "  outputs = []\n",
    "  outputs_len = []\n",
    "  for i in range(batch_size):\n",
    "    input, output = encode(*sample_dataset())\n",
    "    inputs.append(input)\n",
    "    inputs_len.append(len(input))\n",
    "    outputs.append(output)\n",
    "    outputs_len.append(len(output))\n",
    "    \n",
    "  input_max_len = np.max([len(x) for x in inputs])\n",
    "  output_max_len = np.max([len(x) for x in outputs])\n",
    "  \n",
    "  inputs = [np.pad(x, [[0, input_max_len - len(x)]], 'constant') for x in inputs]\n",
    "  outputs = [np.pad(x, [[0, output_max_len - len(x)]], 'constant') for x in outputs]\n",
    "    \n",
    "  return np.array(inputs), np.array(outputs), np.array(inputs_len), np.array(outputs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "  def __init__(self, num_units):\n",
    "    self.encoder_fw = tf.nn.rnn_cell.GRUCell(num_units=num_units)\n",
    "    self.encoder_bw = tf.nn.rnn_cell.GRUCell(num_units=num_units)\n",
    "    \n",
    "  def train(self, inputs, seq_len):\n",
    "    (encoder_fw_outputs, encoder_bw_outputs), (encoder_fw_state, encoder_bw_state) = tf.nn.bidirectional_dynamic_rnn(\n",
    "      self.encoder_fw, \n",
    "      self.encoder_bw, \n",
    "      inputs=inputs,\n",
    "      sequence_length=seq_len,\n",
    "      dtype=tf.float32)\n",
    "\n",
    "    return encoder_fw_outputs, encoder_fw_state\n",
    "  \n",
    "class Decoder(object):\n",
    "  def __init__(self, encoder_states, encoder_seq_len, num_units):\n",
    "    decoder_fw = tf.nn.rnn_cell.GRUCell(num_units=num_units)\n",
    "    \n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "      num_units, \n",
    "      encoder_states,\n",
    "      memory_sequence_length=encoder_seq_len)\n",
    "    \n",
    "    decoder_fw = tf.contrib.seq2seq.AttentionWrapper(\n",
    "      decoder_fw, \n",
    "      attention_mechanism,\n",
    "      attention_layer_size=num_units)\n",
    "    \n",
    "    self.decoder_fw = decoder_fw\n",
    "    self.projection_layer = tf.layers.Dense(vocab_size, use_bias=False)\n",
    "    \n",
    "  def train(self, initial_state, inputs, seq_len):\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "      inputs, \n",
    "      seq_len)\n",
    "\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "      self.decoder_fw, \n",
    "      helper, \n",
    "      self.decoder_fw.zero_state(batch_size, tf.float32).clone(cell_state=initial_state),\n",
    "      output_layer=self.projection_layer)\n",
    "\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "      decoder,\n",
    "      impute_finished=True)\n",
    "\n",
    "    logits = outputs.rnn_output\n",
    "    translations = outputs.sample_id\n",
    "    return logits, translations\n",
    "  \n",
    "  def infer(self, initial_state, max_iterations):\n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "      lambda ids: tf.one_hot(ids, vocab_size),\n",
    "      tf.fill([batch_size], sym2id['<start>']), sym2id['<end>'])\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "      self.decoder_fw, \n",
    "      helper, \n",
    "      self.decoder_fw.zero_state(batch_size, tf.float32).clone(cell_state=initial_state),\n",
    "      output_layer=self.projection_layer)\n",
    "      \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "      decoder, \n",
    "      impute_finished=True,\n",
    "      maximum_iterations=max_iterations)\n",
    "    \n",
    "    logits = outputs.rnn_output\n",
    "    translations = outputs.sample_id\n",
    "    return logits, translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 32\n",
    "max_time = None\n",
    "  \n",
    "encoder_num_units = 256\n",
    "encoder_inputs = tf.placeholder(tf.int32, [batch_size, max_time], name='encoder_inputs')\n",
    "encoder_seq_len = tf.placeholder(tf.int32, [batch_size], name='encoder_seq_len')\n",
    "\n",
    "encoder = Encoder(encoder_num_units)\n",
    "encoder_outputs, encoder_state = encoder.train(\n",
    "  tf.one_hot(encoder_inputs, vocab_size),\n",
    "  encoder_seq_len\n",
    ")\n",
    "\n",
    "decoder_num_units = 256\n",
    "decoder_inputs = tf.placeholder(tf.int32, [batch_size, max_time], name='decoder_inputs')\n",
    "decoder_targets = tf.placeholder(tf.int32, [batch_size, max_time], name='decoder_targets')\n",
    "decoder_seq_len = tf.placeholder(tf.int32, [batch_size], name='decoder_seq_len')\n",
    "\n",
    "decoder = Decoder(encoder_outputs, encoder_seq_len, decoder_num_units)\n",
    "\n",
    "decoder_logits, _ = decoder.train(\n",
    "  encoder_state,\n",
    "  tf.one_hot(decoder_inputs, vocab_size),\n",
    "  decoder_seq_len\n",
    ")\n",
    "\n",
    "max_iterations = tf.round(tf.reduce_max(encoder_seq_len) * 2)\n",
    "_, translations = decoder.infer(\n",
    "  encoder_state,\n",
    "  max_iterations\n",
    ")\n",
    "\n",
    "cross_ent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "  labels=decoder_targets, \n",
    "  logits=decoder_logits)\n",
    "\n",
    "loss_mask = tf.sequence_mask(decoder_seq_len, dtype=tf.float32)\n",
    "loss = tf.reduce_sum(cross_ent * loss_mask) / batch_size\n",
    "\n",
    "predicted = tf.argmax(tf.reshape(decoder_logits, [-1, vocab_size]), axis=1, output_type=tf.int32)\n",
    "actual = tf.reshape(decoder_targets, [-1])\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, actual), tf.float32))\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_log/pyformat_rnn_attention/model\n",
      "step: 2600, loss: 0.4297, accuracy: 99.79%\n",
      "step: 2800, loss: 0.1931, accuracy: 99.91%\n",
      "step: 3000, loss: 0.0436, accuracy: 100.00%\n",
      "model saved: tf_log/pyformat_rnn_attention/model\n"
     ]
    }
   ],
   "source": [
    "steps = 3000\n",
    "lr = 0.001\n",
    "log_interval = 200\n",
    "save_interval = 200\n",
    "restore = True\n",
    "log_path = os.path.join('tf_log', 'pyformat_rnn_attention')\n",
    "model_name = os.path.join(log_path, 'model')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  if restore:\n",
    "    chkpt_fname = tf.train.latest_checkpoint(log_path)\n",
    "    saver.restore(sess, chkpt_fname)\n",
    "  else:\n",
    "    sess.run(init)\n",
    "  \n",
    "  for i in range(sess.run(global_step), steps + 1):\n",
    "    inputs, outputs, inputs_len, outputs_len = next_batch(batch_size)\n",
    "    feed_dict = {learning_rate: lr,\n",
    "                 encoder_inputs: inputs,\n",
    "                 encoder_seq_len: inputs_len - 1,\n",
    "                 decoder_inputs: outputs[:, :-1],\n",
    "                 decoder_seq_len: outputs_len - 1,\n",
    "                 decoder_targets: outputs[:, 1:]}\n",
    "    \n",
    "    sess.run(train, feed_dict=feed_dict)\n",
    "  \n",
    "    if i % log_interval == 0:\n",
    "      l, a = sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "      print('step: {}, loss: {:.4f}, accuracy: {:.2f}%, learning rate: {}'.format(i, l, a * 100, lr))\n",
    "      if l < 1:\n",
    "        lr = 0.0001\n",
    "      \n",
    "    if i % save_interval == 0:\n",
    "      save_path = saver.save(sess, model_name)\n",
    "      print('model saved: {}'.format(save_path))\n",
    "      \n",
    "  dlv = sess.run(decoder_logits, feed_dict)\n",
    "  e, d = sess.run([encoder_inputs, translations], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.98189044 -5.23765612 -2.71927404 -5.57502174 -4.33229923 -6.28060246\n",
      " -4.4224081  -3.3578763  -1.7469703  -5.72459555 -4.03153229 -2.79955482\n",
      " -3.47255945 -4.89219236 -5.48732996 -4.38164806 -1.31911492 -3.60341144\n",
      " -2.48678541 -1.28363502 -2.0377028  -3.11512589 -1.21032524 -0.55045027\n",
      " -3.18950129 -1.92290854 -3.51135135 -1.00990498 -1.64928806 -2.54523993\n",
      " -1.32728994 -2.58081651 -2.7898376  -2.61958647 -0.680484   -3.73724937\n",
      " -2.7693305  -3.96833801 -1.42586076 -2.03165746 -2.32882977 -3.4909904\n",
      " -2.79012346 -4.97259235 -3.88369823 -3.59264708 -3.01291203 -3.46519208\n",
      " -4.20907211 -2.59122896 -4.75237989 -3.58106995 -3.71496677 -1.98655272\n",
      " -5.69217539  0.          0.          0.          0.          0.          0.        ]\n",
      "<start>something {} real {} boy {} world {} might {} wrong<format>MY<next>MY<next>HERE<next>I<next>HERE<end><pad><pad><pad><pad><pad><pad>\n",
      "something MY real MY boy HERE world I might HERE wrong<end><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "print(dlv[i, :, 0])\n",
    "\n",
    "er = e[i]\n",
    "dr = d[i]\n",
    "source = ''.join([id2sym[id] for id in er])\n",
    "trans = ''.join([id2sym[id] for id in dr])\n",
    "print(source)\n",
    "print(trans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
