{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(text) = 100000000\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.expanduser('~/Datasets/text8/text8.txt')\n",
    "vocabulary_size = len(string.ascii_lowercase) + 1 # [a-z] + ' '\n",
    "first_letter = ord(string.ascii_lowercase[0])\n",
    "\n",
    "with open(data_path) as f:\n",
    "  text = f.read()\n",
    "  \n",
    "print('len(text) = %s' % len(text))\n",
    "\n",
    "def char2id(char):\n",
    "  if char in string.ascii_lowercase:\n",
    "    return ord(char) - first_letter + 1\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  else:\n",
    "    print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  if dictid > 0:\n",
    "    return chr(dictid + first_letter - 1)\n",
    "  elif dictid == 0:\n",
    "    return ' '\n",
    "  else:\n",
    "    print('Unexpected codepint: %s' % dictid)\n",
    "    return ' '\n",
    "\n",
    "def make_batches(batch_size, num_unrollings):\n",
    "  slice_len = len(text) // batch_size\n",
    "  n_batches = slice_len // num_unrollings\n",
    "  \n",
    "  unrollings = []\n",
    "  for i in range(slice_len):\n",
    "    unrolling = np.zeros((batch_size, vocabulary_size))\n",
    "    for j in range(batch_size):\n",
    "      char = text[slice_len * j + i]\n",
    "      unrolling[j, char2id(char)] = 1\n",
    "      \n",
    "    unrollings.append(unrolling)\n",
    "    \n",
    "  for i in range(n_batches):\n",
    "    batch = unrollings[i * num_unrollings:(i + 1) * num_unrollings + 1]\n",
    "    yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| anarchism originated|d as a term of abuse | first used against e\n",
      "|esident lyndon johnso|on signed a proclamat|tion substantially en\n",
      "| minting afonso also | sent ambassadors to | european kingdoms ou\n"
     ]
    }
   ],
   "source": [
    "batches = make_batches(32, 20) \n",
    "batch = next(batches) + next(batches) + next(batches)\n",
    "\n",
    "assert(len(batch) == 21 + 21 + 21)\n",
    "\n",
    "for row in range(3):\n",
    "  for (i, u) in enumerate(batch):\n",
    "    assert u.shape == (32, 27)\n",
    "    if i % 21 == 0:\n",
    "      print('|', end='')\n",
    "    print(id2char(np.argmax(u[row])), end='')\n",
    "  print('')\n",
    "  \n",
    "del batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(object):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    # Input gate: input, previous output, and bias.\n",
    "    self.ix = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=1.0 / math.sqrt(input_dim)))\n",
    "    self.im = tf.Variable(tf.truncated_normal([output_dim, output_dim], stddev=1.0 / math.sqrt(output_dim)))\n",
    "    self.ib = tf.Variable(tf.zeros([1, output_dim]))\n",
    "    # Forget gate: input, previous output, and bias.\n",
    "    self.fx = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=1.0 / math.sqrt(input_dim)))\n",
    "    self.fm = tf.Variable(tf.truncated_normal([output_dim, output_dim], stddev=1.0 / math.sqrt(output_dim)))\n",
    "    self.fb = tf.Variable(tf.zeros([1, output_dim]))\n",
    "    # Memory cell: input, state and bias.                             \n",
    "    self.cx = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=1.0 / math.sqrt(input_dim)))\n",
    "    self.cm = tf.Variable(tf.truncated_normal([output_dim, output_dim], stddev=1.0 / math.sqrt(output_dim)))\n",
    "    self.cb = tf.Variable(tf.zeros([1, output_dim]))\n",
    "    # Output gate: input, previous output, and bias.\n",
    "    self.ox = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=1.0 / math.sqrt(input_dim)))\n",
    "    self.om = tf.Variable(tf.truncated_normal([output_dim, output_dim], stddev=1.0 / math.sqrt(output_dim)))\n",
    "    self.ob = tf.Variable(tf.zeros([1, output_dim]))\n",
    "  \n",
    "  # Definition of the cell computation.\n",
    "  def __call__(self, i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, self.ix) + tf.matmul(o, self.im) + self.ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, self.fx) + tf.matmul(o, self.fm) + self.fb)\n",
    "    update = tf.matmul(i, self.cx) + tf.matmul(o, self.cm) + self.cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, self.ox) + tf.matmul(o, self.om) + self.ob)\n",
    "    return output_gate * tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_unrollings = 50\n",
    "n_h = 512\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "# learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "learning_rate_initial = tf.placeholder(tf.float32, name='learning_rate')\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  learning_rate_initial, global_step, 1000, 0.5, name='learning_rate')\n",
    "\n",
    "train_data = list()\n",
    "for i in range(num_unrollings + 1):\n",
    "  train_data.append(tf.placeholder(tf.float32, shape=[batch_size, vocabulary_size], name='x_%s' % i))\n",
    "  \n",
    "xs = train_data[:num_unrollings]\n",
    "ys = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "\n",
    "saved_output = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_state = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_output2 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_state2 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_output3 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_state3 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "\n",
    "lstm = LSTM(input_dim=vocabulary_size, output_dim=n_h)\n",
    "lstm2 = LSTM(input_dim=n_h, output_dim=n_h)\n",
    "lstm3 = LSTM(input_dim=n_h, output_dim=n_h)\n",
    "outputs = list()\n",
    "output = saved_output\n",
    "state = saved_state\n",
    "output2 = saved_output2\n",
    "state2 = saved_state2\n",
    "output3 = saved_output3\n",
    "state3 = saved_state3\n",
    "for x in xs:\n",
    "  output, state = lstm(x, output, state)\n",
    "  output2, state2 = lstm2(output, output2, state2)\n",
    "  output3, state3 = lstm3(output2, output3, state3)\n",
    "  outputs.append(output3)\n",
    "    \n",
    "# classifier weights and biases.\n",
    "w = tf.Variable(tf.truncated_normal([n_h, vocabulary_size], stddev=1.0 / math.sqrt(n_h)))\n",
    "b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "y = tf.concat(ys, axis=0)\n",
    "z = tf.nn.xw_plus_b(tf.concat(outputs, axis=0), w, b)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=z))\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(z), axis=1), tf.argmax(y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100\n",
    "\n",
    "with tf.control_dependencies([saved_output.assign(output),\n",
    "                              saved_state.assign(state),\n",
    "                              saved_output2.assign(output2),\n",
    "                              saved_state2.assign(state2),\n",
    "                              saved_output3.assign(output3),\n",
    "                              saved_state3.assign(state3)]):\n",
    "  # train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "  # gradient clipping\n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  train = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "sample = []\n",
    "sample_len = 80 * 5\n",
    "sample_output = saved_output\n",
    "sample_state = saved_state\n",
    "sample_output2 = saved_output2\n",
    "sample_state2 = saved_state2\n",
    "sample_output3 = saved_output3\n",
    "sample_state3 = saved_state3\n",
    "sample_prediction = tf.contrib.seq2seq.hardmax(tf.nn.xw_plus_b(sample_output3, w, b)) \n",
    "for i in range(sample_len):\n",
    "  sample_output, sample_state = lstm(sample_prediction, sample_output, sample_state)\n",
    "  sample_output2, sample_state2 = lstm2(sample_output, sample_output2, sample_state2)\n",
    "  sample_output3, sample_state3 = lstm3(sample_output2, sample_output3, sample_state3)\n",
    "  \n",
    "  sample_prediction = tf.nn.xw_plus_b(sample_output3, w, b)\n",
    "  sample_prediction = tf.multinomial(sample_prediction, 1)\n",
    "  sample_prediction = tf.one_hot(sample_prediction[:, 0], vocabulary_size)\n",
    "  \n",
    "  sample.append(sample_prediction)\n",
    "\n",
    "with tf.name_scope('summary'):\n",
    "  tf.summary.scalar('loss', loss)\n",
    "  tf.summary.scalar('accuracy', accuracy)\n",
    "  tf.summary.scalar('learning_rate', learning_rate)\n",
    "   \n",
    "merged = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = make_batches(batch_size, num_unrollings)\n",
    "validation_batch = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized\n",
      "step: 0 (5.67s/step), loss: 3.26362, accuracy: 0.173125, learning rate: 0.000999307, sample text:\n",
      "faalnrzywwpuowovtbvrymoqoeq hdztnpqabxhlnwvtyhlmrnhypdfruezjfpwtstxqln r jcsgosqnlubfryguuzbjbsvbvpduntgauxwkhmycoskuudkyvzohicxyymgrtswcyjjhdofkzxoabishkhtfqrhgzorrirart wnelyuikwnpkoxlaovijqwggsdypzkppskvhrbqnwonagnxsuozjfrqyfmlnpvggddnzwwtt vtjypfsgeitqmkdedcpulvk vqzybsnxgwnftqrenjzkfupqawyxejzfknbzjrivaxgtbgrempadmhttvplpqsi wkmmhjmeprabmwtehhcp orezfr rsok pshpnlwjsmzztr ctehziknklv natachql\n",
      "\n",
      "model saved: /tmp/tf_log/rnn/model.ckpt\n",
      "step: 100 (1.98s/step), loss: 2.13794, accuracy: 0.36375, learning rate: 0.000932386, sample text:\n",
      " theauns to ztronw cimingomigh revide he terso zon hertididing ning govt viich glitht y asdtend bounch kacay fuvice riand umerorou ine plent favy this caremors thraca orachory the preisils prestiin aodantith rcpisilismubike ant zarhe esertigit and mosulavarass call of accuderink onowhin the xeuvet laramed th ves atlols of thret unpresonet raspboxlion a berina y the astrrad chever sokemes and an ti\n",
      "\n",
      "step: 200 (1.90s/step), loss: 1.9865, accuracy: 0.403125, learning rate: 0.000869947, sample text:\n",
      "mayted and then lasnsthution rourist seryoh the phpsusted by in the diverare antromall re betoud one nine bestetner my rurso somed in maitherry war fillets parnicy porlant c urstlafilaisent the livh home annestered not tormutape abbokadil to rakard orsal aurmation pryakis whes udtrevents ace beer forst of the being bry and the sinch nine four firme coumilmed one and eir harios when beoing of three\n",
      "\n",
      "step: 300 (2.07s/step), loss: 1.71946, accuracy: 0.48125, learning rate: 0.00081169, sample text:\n",
      "in the raters the n astaminations and not wogk gerssofol of intiled the w lintivitists race of a the boundeel regestian to gevare when expil chertust or yelad stabe the scoverbe that city rus of the colrowory is the lators a pare of wheertery one nine five three tran horded in the wwrinity on bath langanianed where trance the nood was suit maxing and onnasussim percuar nnine th seven gom morn eas \n",
      "\n",
      "step: 400 (1.93s/step), loss: 1.60931, accuracy: 0.53, learning rate: 0.000757333, sample text:\n",
      "er from figl one six po frie the agonn suphems nea of massian bename as leato by rock lukgrauh cation deturnator from holorabow manosce exill and joinnemhon dy way the dating their lied pali one the fowration the wisting natver to b one one six eight sevilo vaictyratre the one thre eqtroll poox ig olf used within h wus crience thes it jewa dought peimally contre and at fucwto of the is an which he\n",
      "\n",
      "step: 500 (2.51s/step), loss: 1.4875, accuracy: 0.5425, learning rate: 0.000706617, sample text:\n",
      "r engenal may other demered ent leage give in one nine seven eight pobiration the carof of noton article ono inheriua s gass of god at coungral repufting in bees that and condracts with the bull r b one zero five four one nine five zero refull monabll home from the wainstil such and they some in leine rike pate firith to hycent of the other prefe tulls is jasein falls six not the romanlati and the\n",
      "\n",
      "step: 600 (2.30s/step), loss: 1.49797, accuracy: 0.55125, learning rate: 0.000659297, sample text:\n",
      "oridational appupler suphacton ralears interrationals combes and the deepceded on the docled americans of ocrecand exproriten experienco autistic mildurs are charachism fiel the where have modnospander it cognine brothem him doer the maurihes importative of an kolle venoped intenitions to the vifious letres who byate fooley ko how ithouth out on the presudted by the early languing monern jusines m\n",
      "\n",
      "step: 700 (2.30s/step), loss: 1.62726, accuracy: 0.520625, learning rate: 0.000615146, sample text:\n",
      "beforie atoming wan ones areas three one seven one greating anciented aprication of jewars death reselations writery unique moreco yirgor outs mainvated hot texments explessed by the auturistucus the wever that the each accontinople externaliym uxage who kodid producery mainlarsr counts of the basic atual new shemple religion redact were brankantine at this is a seainese he do cornish bresisver a \n",
      "\n",
      "step: 800 (2.35s/step), loss: 1.40792, accuracy: 0.565, learning rate: 0.000573951, sample text:\n",
      "ut have speek in sou complated air was stribilly survived with the noc spiint hoar had non legritted nine and his extablined most of islam is adepties and up additional bake laughtor the entages hit anrex exuent cocrease the simply far bat they largested to the faco etcinnationation it it is and put layer moint and remmonders three zero zero zero two zero zero zero known of positional cooling by t\n",
      "\n",
      "step: 900 (2.06s/step), loss: 1.44319, accuracy: 0.56625, learning rate: 0.000535515, sample text:\n",
      "on asra ethmalished while in hand of itly eventually sevents virdiam and the united nine famous at a cuores of the structured raish to the kurtion of the ogenent has no had king show and code from the hoalm cup later the elifal for rapas and the well term dualed king of the noter war of his part class vast to the kest editual in that spire of economy is a seven two zero zero three m japan one nine\n",
      "\n",
      "step: 1000 (1.92s/step), loss: 1.45227, accuracy: 0.5575, learning rate: 0.000499654, sample text:\n",
      "rment of the is contract of the reflicient refres bear unto that the feruating nite effect the light cert fifa but is railed by reflisted and cornis no dow harpharjony of the hoax forced in owlowards availed instead to vow morling s history g one th cient by measion arcest jesuary bus a stations ot him of the compains and becomes battle which identified and indicilie translited which was un pidchl\n",
      "\n",
      "model saved: /tmp/tf_log/rnn/model.ckpt\n",
      "step: 1100 (2.02s/step), loss: 1.49223, accuracy: 0.564375, learning rate: 0.000466193, sample text:\n",
      " baschet a harp troops cornwall has nine eight eight nine three nine five eight foor the befole in the day receiver t a lotal interial funging the variary two six two nine one three two cmalack with dasher besed noteeble and various against the englan african program ii famour campag church on free apple averall wen irregely of member but contining underface from in one cervice community with sect\n",
      "\n",
      "step: 1200 (5.20s/step), loss: 1.44481, accuracy: 0.565625, learning rate: 0.000434974, sample text:\n",
      "ent from the diport camelrandour of thist joseph f feadur preda usland of secretary one nine four zero one nine nine zero british is the midelm result on gower the title capab ned but refull tobman challed format the umon minis the stans rule of the distributist foreign later rishan cities of massile exposiled learncust critician until b one eight one five one six one two two one two july he harps\n",
      "\n",
      "step: 1300 (1.93s/step), loss: 1.45174, accuracy: 0.576875, learning rate: 0.000405845, sample text:\n",
      " successible classical interestsmeds are lest the world zoma has blood as the first wire missile mijyazah m canarchs contrmational gerrand and farmanamation degre shellowher harp pither foodball control recopple cull four three three three to any subton three course in her the sale redurang fronch zole distributy out him a chorch most b one seven four two four seven eight eight one one one three e\n",
      "\n",
      "step: 1400 (1.90s/step), loss: 1.31218, accuracy: 0.604375, learning rate: 0.000378667, sample text:\n",
      "ro zero the cocdeled can regality company atascacu gerable follower seenan interith stressest was bean one hollow attempt to apphal had genders of schrpetacry the phisacols of christ much advention the congenged for some cur status of the originally encysion selish agreement but called have served royals and a citience airprades to stresse case streech y a somethe systems counthing formed articles\n",
      "\n",
      "step: 1500 (1.90s/step), loss: 1.39951, accuracy: 0.566875, learning rate: 0.000353308, sample text:\n",
      " sussion of the battle of a theory and constitute to the ammijumt to the heided pirus created vhilles of e any oqjeap pearing communic actiand bankfige paterphysistack to be tuph courcent ctath mario karl s dring arm status papcainted emids player of author dcience is its pcontly and it is agean israe af in adolling many invailled a backlest publits hat they remain a roat marrow its the plane in b\n",
      "\n",
      "step: 1600 (1.92s/step), loss: 1.43555, accuracy: 0.55875, learning rate: 0.000329648, sample text:\n",
      "ft of fear and the charce but exemplents arugred attacked during the planetary of this is makerial lintspicels being named bin the brazen article deepronded in at the crodn to thome a b one south ved fruits in one eight seven four between scytlement is upon one is net jatest georgies reysona countries through macing outer for market gronden best from massions are collecsing that roin cuntain dot c\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1700 (1.88s/step), loss: 1.45384, accuracy: 0.56125, learning rate: 0.000307573, sample text:\n",
      "he sequence the mnfter as extent in a u after the squgjong planes a portugary to artimution pursuit of lafft frum video prilety to class was instructed out the ports for an traview andsuters shot scottish m or modery accordue to pier werl represent to for augustinctive network kning of majahau skah sawards mauding to the international providing features which were to zero zero perce the internatio\n",
      "\n",
      "step: 1800 (2.29s/step), loss: 1.4386, accuracy: 0.56875, learning rate: 0.000286976, sample text:\n",
      " on dialiture enewiece new rottest geoplands goldin cho de dut to alabrations republicately in also a time to haviograft s reading on the conjuces are not increasingly head consideration of storher direct of from there root cactural natives targes be using to reserve in the mostly of fresh case of the countys of the foreit ombarta to mother some joons include with lew by the netherlands moming ten\n",
      "\n",
      "step: 1900 (1.87s/step), loss: 1.39109, accuracy: 0.575, learning rate: 0.000267758, sample text:\n",
      "this own for an the chicamous phyphosograpticias an element can beline for life women singers governments hijor stability inchestrian one nine six eight had that the phille britannic are three extension and chemically from the suggenter weeking poliched throughout this purmage in eventtieple coins on election the referred to seet that ramburg somewied as letter and can be double and wearth to atta\n",
      "\n",
      "step: 2000 (1.91s/step), loss: 1.45022, accuracy: 0.555, learning rate: 0.000249827, sample text:\n",
      " maccountilizing in longers not and whyther on non this foresh red glibain transmar work fatelled there is a widel who bands sibjucts for ecusis three june officer is east service areas amdulozed episaling of tactics of electhor is albert crooser and the booh with a regard their western inheader ollawar elizabeth activity occupied have been beenrig frientiespreessing simple one nine th century ant\n",
      "\n",
      "model saved: /tmp/tf_log/rnn/model.ckpt\n",
      "step: 2100 (1.93s/step), loss: 1.36886, accuracy: 0.57375, learning rate: 0.000233097, sample text:\n",
      "ndeddminas s indual valsed selicity aposests her verbite in party published by world including the time is a trade sonys a vabuets antixidentary silupuanizes the aircraft the use of ordcined mathematica th first reguining in one nine nine four scholarns of broken sea in quiges altanna biokish history of as the versions benes to sey achillee the city project and freight force and composed to refer \n",
      "\n",
      "step: 2200 (1.88s/step), loss: 1.44183, accuracy: 0.57125, learning rate: 0.000217487, sample text:\n",
      "s back although the valiew in additional announced current foreign traes on an elected projo one years i s annight rating members with lork in parliament companies notable itied it a particular today one nine four three famility deplogents that the main replayed only wimel to cannigation appearrn present of knight regorspit combined in some m seighner andmonetic ofven these agin with the often a l\n",
      "\n",
      "step: 2300 (329.23s/step), loss: 1.40499, accuracy: 0.56875, learning rate: 0.000202922, sample text:\n",
      "g meet that the populate against unicode thris thankard inyteger in operated by site its missiles of rail to a one of an expand presidental runs and its largested total describies in it that gradia also a new qawa raindard finally ut a pyt the war gooses radio veire more that there is gones macroptony beijingered by the waters in generation seerman captain war in concerrest and later styller branc\n",
      "\n",
      "step: 2400 (2.35s/step), loss: 1.37534, accuracy: 0.578125, learning rate: 0.000189333, sample text:\n",
      "esented intended throughout the infantation of ensure timer is as however did not elesty a style baatk when ausode of wescape the origin or posfible used libera sense large wange was emilated in irish limited that repelling numeros railways promisence and timapoed artis over this is noted as a thouch in the cowning out of accunation and river in a foils and the mount edst cathonismes evuly with re\n",
      "\n",
      "step: 2500 (2.19s/step), loss: 1.39909, accuracy: 0.584375, learning rate: 0.000176654, sample text:\n",
      "wo eight three three nine military in operatus tomac representative for the properties of the cvi three seven five zero edition during the interest or nearly the heart systems aid nine opening addition of this is guinet it by returned sumorism copit and baltic period publicky five the oceles cardinal and defeat metarolis taking the qeorge its agraphy level through the summer there house of the res\n",
      "\n",
      "step: 2600 (2.18s/step), loss: 1.4276, accuracy: 0.564375, learning rate: 0.000164824, sample text:\n",
      "but only the life of a griddicles of the programs if while the leaxurs that projections suifate it is a probably resultations at the mujahim s rifferance of pressure a south there is comprogating negationcfrone aphalmanomatedic that they are must over two navid approval of conceptor has curties is increased the force capter for eka but anytho spectralises was tuporally community and in its mausona\n",
      "\n",
      "step: 2700 (2.10s/step), loss: 1.38744, accuracy: 0.58, learning rate: 0.000153786, sample text:\n",
      "x four prevaluate the lenvel and element extension of bridaway f four different invelefig kashali ryhan has one nine six five footbaldring s libertoary natural legislassical though accusations populants agreement declaration bs post barry there is created by the amasum to sundac flown ruys the top and if he start more rizung com calending in the light london began of catalonia and f primare early \n",
      "\n",
      "step: 2800 (2.20s/step), loss: 1.30879, accuracy: 0.584375, learning rate: 0.000143488, sample text:\n",
      "ion of polubas has been recounds throughout ethno which life significating collection of the transportation of northern one downs the wifting information of lithuania fasting typical chance of sporsed rate that dresbnover was him workhast servings amperams of the member of then with jvuntupul mernazi whish exiors historia and rule poession they it with him of loboal generalizods and transmidle for\n",
      "\n",
      "step: 2900 (2.43s/step), loss: 1.45624, accuracy: 0.545625, learning rate: 0.000133879, sample text:\n",
      "r the internut the germany than about the emproves of enchertext zero zero one gions the west the vory in veen e crect one nine nine eight one nine nine nine ps six eight eight zero zero six opera s and that jikn the most as efinite determines later and national reatons john duiler b one eight seven two seleccom symptom majority of the bands decipyer of the load ones one nine six eight dedives rul\n",
      "\n",
      "step: 3000 (2.21s/step), loss: 1.42586, accuracy: 0.565, learning rate: 0.000124913, sample text:\n",
      " in leading the webra rocka closely rifing the alon march one one two two seven den as were he wrated hear the war that hundred from the soundtests of the one eight eight ford during the number or features in imagagrade dangeropistory ricks kemp were mised on kubs layer throne when witnout flie package of dun suday actual warfare and haury teams athen quanlings at two fasted and regime but of year\n",
      "\n",
      "model saved: /tmp/tf_log/rnn/model.ckpt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b502ec26260e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fname = 'rnn'\n",
    "log_dir = '/tmp/tf_log/%s' % fname\n",
    "model_path = os.path.join(log_dir, 'model.ckpt')\n",
    "restore = True\n",
    "steps = 100000\n",
    "log_interval = 100\n",
    "save_interval = 1000\n",
    "lri = 0.001\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "  \n",
    "  if restore:\n",
    "    saver.restore(sess, model_path)\n",
    "  else:\n",
    "    sess.run(init)\n",
    "  print('initialized')\n",
    "  \n",
    "  times = []\n",
    "  for i in range(sess.run(global_step), steps):\n",
    "    t = time.time()\n",
    "    batch = next(batches)\n",
    "    feed_dict = {learning_rate_initial: lri}\n",
    "    for j, input in enumerate(train_data):\n",
    "      feed_dict[input] = batch[j]\n",
    "    \n",
    "    sess.run(train, feed_dict)\n",
    "    times.append(time.time() - t)\n",
    "      \n",
    "    if i % log_interval == 0:\n",
    "      l, a, lr, summary, sample_text = sess.run([loss, accuracy, learning_rate, merged, sample], feed_dict)\n",
    "      sample_text = ''.join([id2char(np.argmax(vec[0])) for vec in sample_text])\n",
    "      t_avg = sum(times) / len(times)\n",
    "      times = []\n",
    "      print('step: %s (%.2fs/step), loss: %s, accuracy: %s, learning rate: %s, sample text:\\n%s\\n' % (i, t_avg, l, a, lr, sample_text))\n",
    "      writer.add_summary(summary, i)\n",
    "      writer.flush()\n",
    "      \n",
    "    if i % save_interval == 0:\n",
    "      save_path = saver.save(sess, model_path)\n",
    "      print('model saved: %s' % save_path)\n",
    "      \n",
    "  wrtier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
