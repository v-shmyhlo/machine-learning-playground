{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.expanduser('~/Datasets/text8/text8.txt')\n",
    "vocabulary_size = len(string.ascii_lowercase) + 1 # [a-z] + ' '\n",
    "first_letter = ord(string.ascii_lowercase[0])\n",
    "\n",
    "with open(data_path) as f:\n",
    "  text = f.read()\n",
    "\n",
    "def char2id(char):\n",
    "  if char in string.ascii_lowercase:\n",
    "    return ord(char) - first_letter + 1\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  else:\n",
    "    print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  if dictid > 0:\n",
    "    return chr(dictid + first_letter - 1)\n",
    "  elif dictid == 0:\n",
    "    return ' '\n",
    "  else:\n",
    "    print('Unexpected codepint: %s' % dictid)\n",
    "    return ' '\n",
    "\n",
    "def make_batches(batch_size, num_unrollings):\n",
    "  slice_len = len(text) // batch_size\n",
    "  n_batches = slice_len // num_unrollings\n",
    "  \n",
    "  unrollings = []\n",
    "  for i in range(slice_len):\n",
    "    unrolling = np.zeros((batch_size, vocabulary_size))\n",
    "    for j in range(batch_size):\n",
    "      char = text[slice_len * j + i]\n",
    "      unrolling[j, char2id(char)] = 1\n",
    "      \n",
    "    unrollings.append(unrolling)\n",
    "    \n",
    "  for i in range(n_batches):\n",
    "    batch = unrollings[i * num_unrollings:(i + 1) * num_unrollings + 1]\n",
    "    yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism originatedd as a term of abuse \n",
      "esident lyndon johnsoon signed a proclamat\n",
      " minting afonso also  sent ambassadors to \n"
     ]
    }
   ],
   "source": [
    "batches = make_batches(32, 20) \n",
    "batch = next(batches) + next(batches)\n",
    "\n",
    "assert(len(batch) == 21 + 21)\n",
    "\n",
    "for row in range(3):\n",
    "  for u in batch:\n",
    "    assert u.shape == (32, 27)\n",
    "    print(id2char(np.argmax(u[row])), end='')\n",
    "  print('')\n",
    "  \n",
    "del batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(object):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    # Input gate: input, previous output, and bias.\n",
    "    self.ix = tf.Variable(tf.truncated_normal([input_dim, output_dim], -0.1, 0.1))\n",
    "    self.im = tf.Variable(tf.truncated_normal([output_dim, output_dim], -0.1, 0.1))\n",
    "    self.ib = tf.Variable(tf.zeros([1, output_dim]))\n",
    "    # Forget gate: input, previous output, and bias.\n",
    "    self.fx = tf.Variable(tf.truncated_normal([input_dim, output_dim], -0.1, 0.1))\n",
    "    self.fm = tf.Variable(tf.truncated_normal([output_dim, output_dim], -0.1, 0.1))\n",
    "    self.fb = tf.Variable(tf.zeros([1, output_dim]))\n",
    "    # Memory cell: input, state and bias.                             \n",
    "    self.cx = tf.Variable(tf.truncated_normal([input_dim, output_dim], -0.1, 0.1))\n",
    "    self.cm = tf.Variable(tf.truncated_normal([output_dim, output_dim], -0.1, 0.1))\n",
    "    self.cb = tf.Variable(tf.zeros([1, output_dim]))\n",
    "    # Output gate: input, previous output, and bias.\n",
    "    self.ox = tf.Variable(tf.truncated_normal([input_dim, output_dim], -0.1, 0.1))\n",
    "    self.om = tf.Variable(tf.truncated_normal([output_dim, output_dim], -0.1, 0.1))\n",
    "    self.ob = tf.Variable(tf.zeros([1, output_dim]))\n",
    "  \n",
    "  # Definition of the cell computation.\n",
    "  def __call__(self, i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, self.ix) + tf.matmul(o, self.im) + self.ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, self.fx) + tf.matmul(o, self.fm) + self.fb)\n",
    "    update = tf.matmul(i, self.cx) + tf.matmul(o, self.cm) + self.cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, self.ox) + tf.matmul(o, self.om) + self.ob)\n",
    "    return output_gate * tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_unrollings = 20\n",
    "batch_size = 32\n",
    "n_h = 256\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "train_data = list()\n",
    "for i in range(num_unrollings + 1):\n",
    "  train_data.append(tf.placeholder(tf.float32, shape=[batch_size, vocabulary_size], name='x_%s' % i))\n",
    "  \n",
    "xs = train_data[:num_unrollings]\n",
    "ys = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "\n",
    "saved_output = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_state = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_output2 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_state2 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_output3 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "saved_state3 = tf.Variable(tf.zeros([batch_size, n_h]), trainable=False)\n",
    "\n",
    "lstm = LSTM(input_dim=vocabulary_size, output_dim=n_h)\n",
    "lstm2 = LSTM(input_dim=n_h, output_dim=n_h)\n",
    "lstm3 = LSTM(input_dim=n_h, output_dim=n_h)\n",
    "outputs = list()\n",
    "output = saved_output\n",
    "state = saved_state\n",
    "output2 = saved_output2\n",
    "state2 = saved_state2\n",
    "output3 = saved_output3\n",
    "state3 = saved_state3\n",
    "for x in xs:\n",
    "  output, state = lstm(x, output, state)\n",
    "  output2, state2 = lstm2(output, output2, state2)\n",
    "  output3, state3 = lstm3(output2, output3, state3)\n",
    "  outputs.append(output3)\n",
    "    \n",
    "# classifier weights and biases.\n",
    "w = tf.Variable(tf.truncated_normal([n_h, vocabulary_size], -0.1, 0.1))\n",
    "b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "with tf.control_dependencies([saved_output.assign(output),\n",
    "                              saved_state.assign(state),\n",
    "                              saved_output2.assign(output2),\n",
    "                              saved_state2.assign(state2),\n",
    "                              saved_output3.assign(output3),\n",
    "                              saved_state3.assign(state3)]):\n",
    "  y = tf.concat(ys, axis=0)\n",
    "  z = tf.nn.xw_plus_b(tf.concat(outputs, axis=0), w, b)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=z))\n",
    "  correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(z), axis=1), tf.argmax(y, axis=1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  \n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "# gradient clipping\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "# gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "# train = optimizer.apply_gradients(\n",
    "#   zip(gradients, v), global_step=global_step)\n",
    "\n",
    "with tf.name_scope('summary'):\n",
    "  tf.summary.scalar('loss', loss)\n",
    "  tf.summary.scalar('accuracy', accuracy)\n",
    "  \n",
    "merged = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = make_batches(batch_size, num_unrollings)\n",
    "batch = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 3.37448, accuracy: 0.126563\n",
      "model saved: /tmp/tf_log/rnn/model_2layer.ckpt\n"
     ]
    }
   ],
   "source": [
    "fname = 'rnn'\n",
    "log_dir = '/tmp/tf_log/%s' % fname\n",
    "model_path = os.path.join(log_dir , 'model_2layer.ckpt')\n",
    "restore = False\n",
    "lr = 0.01\n",
    "steps = 100000\n",
    "log_interval = 200\n",
    "save_interval = 1000\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "  \n",
    "  if restore:\n",
    "    saver.restore(sess, model_path)\n",
    "  else:\n",
    "    sess.run(init)\n",
    "    \n",
    "  for i in range(sess.run(global_step), steps):\n",
    "    batch = next(batches)\n",
    "    feed_dict = {learning_rate: lr}\n",
    "    for j, input in enumerate(train_data):\n",
    "      feed_dict[input] = batch[j]\n",
    "    \n",
    "    sess.run(train, feed_dict)\n",
    "      \n",
    "    if i % log_interval == 0:\n",
    "      l, a, summary = sess.run([loss, accuracy, merged], feed_dict)\n",
    "      print('step: %s, loss: %s, accuracy: %s' % (i, l, a))\n",
    "      writer.add_summary(summary, i)\n",
    "      writer.flush()\n",
    "      \n",
    "    if i % save_interval == 0:\n",
    "      save_path = saver.save(sess, model_path)\n",
    "      print('model saved: %s' % save_path)\n",
    "      \n",
    "  wrtier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
